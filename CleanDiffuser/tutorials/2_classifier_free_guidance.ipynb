{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2. Classifier-free Guidance\n",
    "\n",
    "## 1 Introduction\n",
    "\n",
    "In this tutorial, we'll explore how to customize a classifier-free guidance (CFG) model for a specific task. Let's first review how CFG works.\n",
    "\n",
    "### 1.1 Classifier-free Guidance\n",
    "We consider a conditional generation task, where we want to sample from a conditional distribution $q_0(\\bm x|\\bm y)$. The score function can be written as\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\nabla_{\\bm x}\\log q_t(\\bm x_t|\\bm y)=\\nabla_{\\bm x}\\log q_t(\\bm x_t) + \\nabla_{\\bm x}\\log q_t(\\bm y|\\bm x_t),\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where the first term on the right side is the score function of unconditional distribution $q_t(\\bm x_t)$ that can be estimated by training an unconditional diffusion model on the dataset. The second term is what the guidance methods need to estimate. CFG uses $\\nabla_{\\bm x}\\log q_t(\\bm y|\\bm x_t)=\\nabla_{\\bm x}\\log q_t(\\bm x_t|\\bm y)-\\nabla_{\\bm x}\\log q_t(\\bm x_t)$. By training a conditional noise prediction model $\\bm\\epsilon_\\theta(\\bm x_t, t, \\bm y)$, the sampling process can be guided with no additional classifier:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\bar{\\bm\\epsilon_\\theta}(\\bm x_t, t, \\bm y)=\\bm\\epsilon_\\theta(\\bm x_t, t)-w\\cdot\\left(\\bm\\epsilon_\\theta(\\bm x_t, t, \\bm y)-\\bm\\epsilon_\\theta(\\bm x_t, t)\\right),\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $w$ is the guidance strength. In practice, we use a dummy condition $\\bm y=\\bm\\Phi$ to represent unconditional generation, i.e., $\\bm\\epsilon_\\theta(\\bm x_t, t,\\bm\\Phi)=\\bm\\epsilon_\\theta(\\bm x_t, t)$.\n",
    "\n",
    "In decision-making, the condition $\\bm y$ may be highly complex multi-modal data, e.g., image-based observations, language instructions, point clouds, and so on. Some works even use large transformers for multimodal fusion processing of conditions, while using small MLPs as the diffusion NN backbone. Therefore, in CleanDiffuser, we believe it is forward-looking and necessary to decouple the neural networks of Diffusion $\\bm\\epsilon_\\theta$ and the conditions $\\bm\\zeta_\\phi$ to facilitate development and debugging. The conditional diffusion models in CleanDiffuser are actually implemented as $\\epsilon_\\theta(\\bm x_t, t, \\bm\\zeta_\\phi(\\bm y))$, and the dummy condition is defined to be zeros $\\bm\\zeta_\\phi(\\bm\\Phi)=\\bm 0$ without loss of generality. This is why in tutorial 1, we need both a `NNDiffusion` and a `NNCondition` to create a diffusion model. The `NNDiffusion` is the $\\bm\\epsilon_\\theta$ here and the `NNCondition` is the $\\bm\\zeta_\\phi$.\n",
    "\n",
    "### 1.2 Diffusion Planners\n",
    "\n",
    "In this tutorial, we'll implement a diffusion planner using CFG. The basic idea of diffusion planners is to generate high-performance decision trajectories and extract the first action in the trajectory to execute. This is actually very similar to MPC and many planning-based model-based RL algorithms. They use searching methods and dynamic models to obtain high-performance trajectories, while diffusion planners use conditional generation to achieve this.\n",
    "\n",
    "Obviously, we need a \"high-performance\" variable as a condition to guide the generation. A simple and commonly used method is to use the discounted return-to-go of trajectories $\\sum_{s=t}^T \\gamma^{s-t} r_s$ in the dataset as the condition. It is actually a Monte Carlo estimation of the value of the trajectory. During training, we normalize the values in the dataset to the range [0, 1], so that a value of 1 represents the highest performance. During inference, we use relatively high normalized values like 0.8-1.0 as conditions to generate high-performance trajectories. For more details, we recommend reading [Diffuser](https://arxiv.org/abs/2205.09991) and [Decision Diffuser](https://openreview.net/forum?id=sP1fo2K9DFG).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Setting up the Environment and Preparing the Dataset\n",
    "\n",
    "We use D4RL-MuJoCo-halfcheetah-medium-expert-v2 as the benchmark. D4RL-MuJoCo is a widely used offline RL benchmark. `halfcheetah-medium-expert-v2` requires to control a halfcheetah robot to move forward as fast as possible, and it provides a medium-expert-quality demonstration dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# MuJoCo 路径\n",
    "mjbin = os.path.expanduser(\"~/.mujoco/mujoco210/bin\")\n",
    "# NVIDIA 驱动库路径\n",
    "nvid = \"/usr/lib/nvidia\"\n",
    "\n",
    "# 获取当前的 LD_LIBRARY_PATH（如果不存在，就设为空字符串）\n",
    "ld = os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "\n",
    "# 构造一个新的路径列表，确保 MuJoCo 和 NVIDIA 都在其中\n",
    "paths = ld.split(\":\") if ld else []\n",
    "for p in (mjbin, nvid):\n",
    "    if p not in paths:\n",
    "        paths.append(p)\n",
    "\n",
    "# 重新设置环境变量\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \":\".join(paths)\n",
    "\n",
    "# （可选）如果 PATH 也需要 ~/.local/bin\n",
    "path = os.environ.get(\"PATH\",\"\").split(\":\")\n",
    "localbin = os.path.expanduser(\"~/.local/bin\")\n",
    "if localbin not in path:\n",
    "    path.insert(0, localbin)\n",
    "    os.environ[\"PATH\"] = \":\".join(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import error. Trying to rebuild mujoco_py.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: All of online environments libraries in D4RL have been moved \u001b]8;;https://github.com/Farama-Foundation/Gymnasium\u001b\\Gymnasium\u001b]8;;\u001b\\, \u001b]8;;https://github.com/Farama-Foundation/MiniGrid\u001b\\MiniGrid\u001b]8;;\u001b\\ and \u001b]8;;https://github.com/Farama-Foundation/Gymnasium-Robotics\u001b\\Gymnasium-Robotics\u001b]8;;\u001b\\, and all offline datasets in D4RL have been moved to \u001b]8;;https://github.com/Farama-Foundation/Minari\u001b\\Minari\u001b]8;;\u001b\\.\n",
      "These new versions include large bug fixes, new versions of Python, and are where all new development will continue. Please upgrade these libraries as soon as you're able to do so.\n",
      "If you'd like to read more about the story behind this switch, please check out \u001b]8;;https://farama.org/Announcing-Minari\u001b\\this blog post\u001b]8;;\u001b\\.\n",
      "/usr/bin/ld: warning: /home/nkd/anaconda3/envs/cleandiffuser/lib/libgomp.so: unsupported GNU_PROPERTY_TYPE (5) type: 0xc0010001\n",
      "/usr/bin/ld: warning: /home/nkd/anaconda3/envs/cleandiffuser/lib/libgomp.so: unsupported GNU_PROPERTY_TYPE (5) type: 0xc0010002\n",
      "/usr/bin/ld: warning: /home/nkd/anaconda3/envs/cleandiffuser/lib/libgcc_s.so.1: unsupported GNU_PROPERTY_TYPE (5) type: 0xc0010001\n",
      "/usr/bin/ld: warning: /home/nkd/anaconda3/envs/cleandiffuser/lib/libgcc_s.so.1: unsupported GNU_PROPERTY_TYPE (5) type: 0xc0010002\n",
      "/usr/bin/ld: warning: /home/nkd/anaconda3/envs/cleandiffuser/lib/libgcc_s.so.1: unsupported GNU_PROPERTY_TYPE (5) type: 0xc0010001\n",
      "/usr/bin/ld: warning: /home/nkd/anaconda3/envs/cleandiffuser/lib/libgcc_s.so.1: unsupported GNU_PROPERTY_TYPE (5) type: 0xc0010002\n",
      "Warning: Mujoco-based envs failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "libglewegl.so: cannot open shared object file: No such file or directory\n",
      "Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'flow'\n",
      "INFO:absl:MUJOCO_GL is not set, so an OpenGL backend will be chosen automatically.\n",
      "/home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/glfw/__init__.py:917: GLFWError: (65550) b'X11: The DISPLAY environment variable is missing'\n",
      "  warnings.warn(message, GLFWError)\n",
      "INFO:absl:Successfully imported OpenGL backend: glfw\n",
      "INFO:absl:MuJoCo library version is: 3.1.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import error. Trying to rebuild mujoco_py.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'carla'\n",
      "pybullet build time: Jan 29 2025 23:20:52\n",
      "/home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/pybullet_envs/env_bases.py:8: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import parse_version\n",
      "/home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/pkg_resources/__init__.py:3147: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "INFO:root:running build_ext\n",
      "INFO:root:building 'mujoco_py.cymj' extension\n",
      "INFO:root:gcc -pthread -B /home/nkd/anaconda3/envs/cleandiffuser/compiler_compat -Wl,--sysroot=/ -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/nkd/anaconda3/envs/cleandiffuser/include -fPIC -O2 -isystem /home/nkd/anaconda3/envs/cleandiffuser/include -fPIC -I/home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py -I/home/nkd/.mujoco/mujoco210/include -I/home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/numpy/core/include -I/home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py/vendor/egl -I/home/nkd/anaconda3/envs/cleandiffuser/include/python3.9 -c /home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py/cymj.c -o /home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_39_linuxgpuextensionbuilder/temp.linux-x86_64-cpython-39/home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py/cymj.o -fopenmp -w\n",
      "INFO:root:gcc -pthread -B /home/nkd/anaconda3/envs/cleandiffuser/compiler_compat -Wl,--sysroot=/ -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/nkd/anaconda3/envs/cleandiffuser/include -fPIC -O2 -isystem /home/nkd/anaconda3/envs/cleandiffuser/include -fPIC -I/home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py -I/home/nkd/.mujoco/mujoco210/include -I/home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/numpy/core/include -I/home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py/vendor/egl -I/home/nkd/anaconda3/envs/cleandiffuser/include/python3.9 -c /home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py/gl/eglshim.c -o /home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_39_linuxgpuextensionbuilder/temp.linux-x86_64-cpython-39/home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py/gl/eglshim.o -fopenmp -w\n",
      "INFO:root:gcc -pthread -B /home/nkd/anaconda3/envs/cleandiffuser/compiler_compat -Wl,--sysroot=/ -shared -Wl,-rpath,/home/nkd/anaconda3/envs/cleandiffuser/lib -Wl,-rpath-link,/home/nkd/anaconda3/envs/cleandiffuser/lib -L/home/nkd/anaconda3/envs/cleandiffuser/lib -Wl,-rpath,/home/nkd/anaconda3/envs/cleandiffuser/lib -Wl,-rpath-link,/home/nkd/anaconda3/envs/cleandiffuser/lib -L/home/nkd/anaconda3/envs/cleandiffuser/lib /home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_39_linuxgpuextensionbuilder/temp.linux-x86_64-cpython-39/home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py/cymj.o /home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_39_linuxgpuextensionbuilder/temp.linux-x86_64-cpython-39/home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py/gl/eglshim.o -L/home/nkd/.mujoco/mujoco210/bin -Wl,--enable-new-dtags,-rpath,/home/nkd/.mujoco/mujoco210/bin -lmujoco210 -lglewegl -o /home/nkd/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py/generated/_pyxbld_2.1.2.14_39_linuxgpuextensionbuilder/lib.linux-x86_64-cpython-39/mujoco_py/cymj.cpython-39-x86_64-linux-gnu.so -fopenmp\n",
      "/usr/bin/ld: warning: /home/nkd/anaconda3/envs/cleandiffuser/lib/libgomp.so: unsupported GNU_PROPERTY_TYPE (5) type: 0xc0010001\n",
      "/usr/bin/ld: warning: /home/nkd/anaconda3/envs/cleandiffuser/lib/libgomp.so: unsupported GNU_PROPERTY_TYPE (5) type: 0xc0010002\n",
      "/usr/bin/ld: warning: /home/nkd/anaconda3/envs/cleandiffuser/lib/libgcc_s.so.1: unsupported GNU_PROPERTY_TYPE (5) type: 0xc0010001\n",
      "/usr/bin/ld: warning: /home/nkd/anaconda3/envs/cleandiffuser/lib/libgcc_s.so.1: unsupported GNU_PROPERTY_TYPE (5) type: 0xc0010002\n",
      "/usr/bin/ld: warning: /home/nkd/anaconda3/envs/cleandiffuser/lib/libgcc_s.so.1: unsupported GNU_PROPERTY_TYPE (5) type: 0xc0010001\n",
      "/usr/bin/ld: warning: /home/nkd/anaconda3/envs/cleandiffuser/lib/libgcc_s.so.1: unsupported GNU_PROPERTY_TYPE (5) type: 0xc0010002\n"
     ]
    },
    {
     "ename": "DependencyNotInstalled",
     "evalue": "libglewegl.so: cannot open shared object file: No such file or directory. (HINT: you need to install mujoco_py, and also perform the setup instructions here: https://github.com/openai/mujoco-py/.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/gym/envs/mujoco/mujoco_env.py:12\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmujoco_py\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/env python\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmujoco_py\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cymj, ignore_mujoco_warnings, functions, MujocoException\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmujoco_py\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerated\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m const\n",
      "File \u001b[0;32m~/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py/builder.py:504\u001b[0m\n\u001b[1;32m    503\u001b[0m mujoco_path \u001b[38;5;241m=\u001b[39m discover_mujoco()\n\u001b[0;32m--> 504\u001b[0m cymj \u001b[38;5;241m=\u001b[39m \u001b[43mload_cython_ext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmujoco_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# Trick to expose all mj* functions from mujoco in mujoco_py.*\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py/builder.py:111\u001b[0m, in \u001b[0;36mload_cython_ext\u001b[0;34m(mujoco_path)\u001b[0m\n\u001b[1;32m    110\u001b[0m         cext_so_path \u001b[38;5;241m=\u001b[39m builder\u001b[38;5;241m.\u001b[39mbuild()\n\u001b[0;32m--> 111\u001b[0m         mod \u001b[38;5;241m=\u001b[39m \u001b[43mload_dynamic_ext\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcymj\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcext_so_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mod\n",
      "File \u001b[0;32m~/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/mujoco_py/builder.py:130\u001b[0m, in \u001b[0;36mload_dynamic_ext\u001b[0;34m(name, path)\u001b[0m\n\u001b[1;32m    129\u001b[0m loader \u001b[38;5;241m=\u001b[39m ExtensionFileLoader(name, path)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mImportError\u001b[0m: libglewegl.so: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01md4rl\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcleandiffuser\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01md4rl_mujoco_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m D4RLMuJoCoDataset\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# horizon=4 is enough for halfcheetah tasks as mentioned in Diffuser paper.\u001b[39;00m\n",
      "File \u001b[0;32m~/ouyangzl/D4RL/d4rl/__init__.py:53\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01md4rl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgym_bullet\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01md4rl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpointmaze_bullet\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SUPPRESS_MESSAGES:\n",
      "File \u001b[0;32m~/ouyangzl/D4RL/d4rl/pointmaze_bullet/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpointmaze\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmaze_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OPEN, U_MAZE, MEDIUM_MAZE, LARGE_MAZE, U_MAZE_EVAL, MEDIUM_MAZE_EVAL, LARGE_MAZE_EVAL\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m register\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01md4rl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m infos\n",
      "File \u001b[0;32m~/ouyangzl/D4RL/d4rl/pointmaze/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmaze_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MazeEnv, OPEN, U_MAZE, MEDIUM_MAZE, LARGE_MAZE, U_MAZE_EVAL, MEDIUM_MAZE_EVAL, LARGE_MAZE_EVAL\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m register\n\u001b[1;32m      4\u001b[0m register(\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaze2d-open-v0\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     entry_point\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md4rl.pointmaze:MazeEnv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     }\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/ouyangzl/D4RL/d4rl/pointmaze/maze_model.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" A pointmass maze env.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmujoco\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mujoco_env\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01md4rl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m offline_env\n",
      "File \u001b[0;32m~/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/gym/envs/mujoco/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmujoco\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmujoco_env\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MujocoEnv\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ^^^^^ so that user gets the correct error\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# message if mujoco is not installed correctly\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmujoco\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AntEnv\n",
      "File \u001b[0;32m~/anaconda3/envs/cleandiffuser/lib/python3.9/site-packages/gym/envs/mujoco/mujoco_env.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmujoco_py\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mDependencyNotInstalled(\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. (HINT: you need to install mujoco_py, and also perform the setup instructions here: https://github.com/openai/mujoco-py/.)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     16\u001b[0m             e\n\u001b[1;32m     17\u001b[0m         )\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     20\u001b[0m DEFAULT_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconvert_observation_to_space\u001b[39m(observation):\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m: libglewegl.so: cannot open shared object file: No such file or directory. (HINT: you need to install mujoco_py, and also perform the setup instructions here: https://github.com/openai/mujoco-py/.)"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import d4rl\n",
    "from cleandiffuser.dataset.d4rl_mujoco_dataset import D4RLMuJoCoDataset\n",
    "\n",
    "\n",
    "# horizon=4 is enough for halfcheetah tasks as mentioned in Diffuser paper.\n",
    "horizon = 4\n",
    "env = gym.make(\"halfcheetah-medium-expert-v2\")\n",
    "dataset = D4RLMuJoCoDataset(env.get_dataset(), terminal_penalty=-100, horizon=horizon)\n",
    "obs_dim, act_dim = dataset.o_dim, dataset.a_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_dim = 17, act_dim = 6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import minari\n",
    "from cleandiffuser.dataset.d4rl_mujoco_dataset import D4RLMuJoCoDataset\n",
    "\n",
    "# horizon=4 is enough for halfcheetah tasks as mentioned in Diffuser paper.\n",
    "horizon = 4\n",
    "terminal_penalty = -100\n",
    "\n",
    "# 1. 用 minari 加载数据并下载（如果本地没有的话）\n",
    "ds = minari.load_dataset(\"mujoco/halfcheetah/medium-v0\", download=True)\n",
    "\n",
    "# 2. 拼接所有 episode\n",
    "obs_list, act_list, rew_list, timeout_list, terminal_list = [], [], [], [], []\n",
    "\n",
    "for ep in ds.iterate_episodes():\n",
    "    obs_list.append(ep.observations)\n",
    "    act_list.append(ep.actions)\n",
    "    rew_list.append(ep.rewards)\n",
    "    timeout_list.append(ep.truncations)    # 使用 truncations 代替 infos['timeouts']\n",
    "    terminal_list.append(ep.terminations)\n",
    "\n",
    "observations = np.concatenate(obs_list, axis=0)\n",
    "actions      = np.concatenate(act_list, axis=0)\n",
    "rewards      = np.concatenate(rew_list, axis=0)\n",
    "timeouts     = np.concatenate(timeout_list, axis=0)\n",
    "terminals    = np.concatenate(terminal_list, axis=0)\n",
    "\n",
    "data_dict = {\n",
    "    \"observations\": observations,\n",
    "    \"actions\":      actions,\n",
    "    \"rewards\":      rewards,\n",
    "    \"timeouts\":     timeouts,\n",
    "    \"terminals\":    terminals\n",
    "}\n",
    "\n",
    "dataset = D4RLMuJoCoDataset(data_dict,\n",
    "                            terminal_penalty=terminal_penalty,\n",
    "                            horizon=horizon)\n",
    "\n",
    "\n",
    "obs_dim, act_dim = dataset.o_dim, dataset.a_dim\n",
    "print(f\"obs_dim = {obs_dim}, act_dim = {act_dim}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Customizing a CFG Model\n",
    "\n",
    "To customize a CFG model, we are actually designing the condition network $\\bm\\zeta_\\phi$. So our first step is to check how the diffusion network uses the condition embedding. Suppose we use `DiT1d` as the diffusion network and we take a look at the forward function of `DiT1d` to see it takes a tensor of shape `(batch_size, embedding_dim)` as the condition embedding. And we use the value tensor of shape `(batch_size, 1)` as the generation condition. So we need to design a condition network that can map the value tensor to the condition embedding tensor. Here we use a simple MLP as the condition network (See `ValueNNCondition` below). Then we can simply combine the `DiT1d` and `ValueNNCondition` to create a diffusion model as we did in tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory shape: torch.Size([1, 4, 23])\n",
      "First observation MSE: 0.0\n"
     ]
    }
   ],
   "source": [
    "from cleandiffuser.nn_condition import BaseNNCondition, get_mask\n",
    "from cleandiffuser.utils import at_least_ndim\n",
    "from cleandiffuser.nn_diffusion import DiT1d\n",
    "from cleandiffuser.diffusion import ContinuousDiffusionSDE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ValueNNCondition(BaseNNCondition):\n",
    "    \"\"\" Simple MLP NNCondition for value conditioning.\n",
    "    \n",
    "    value (bs, 1) -> ValueNNCondition -> embedding (bs, emb_dim)\n",
    "\n",
    "    Args:\n",
    "        emb_dim (int): Embedding dimension.\n",
    "        dropout (float): Label dropout rate.\n",
    "    \n",
    "    Example:\n",
    "        >>> value = torch.rand(32, 1)\n",
    "        >>> condition = ValueNNCondition(emb_dim=64, dropout=0.25)\n",
    "        >>> # If condition.training, embedding will be masked to be dummy condition \n",
    "        >>> # with label dropout rate 0.25.\n",
    "        >>> embedding = condition(value) \n",
    "        >>> embedding.shape\n",
    "        torch.Size([32, 64])\n",
    "    \"\"\"\n",
    "    def __init__(self, emb_dim: int, dropout: float = 0.25):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(1, 256), nn.SiLU(),\n",
    "            nn.Linear(256, 256), nn.SiLU(),\n",
    "            nn.Linear(256, emb_dim))\n",
    "    def forward(self, condition: torch.Tensor, mask: torch.Tensor = None):\n",
    "        mask = get_mask(\n",
    "            mask, (condition.shape[0],), self.dropout, self.training, condition.device)\n",
    "        mask = at_least_ndim(mask, condition.dim())\n",
    "        return condition * mask\n",
    "    \n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "nn_diffusion = DiT1d(\n",
    "    obs_dim + act_dim, emb_dim=128, d_model=320, n_heads=10, depth=2, \n",
    "    timestep_emb_type=\"untrainable_fourier\")\n",
    "nn_condition = ValueNNCondition(emb_dim=128, dropout=0.25)\n",
    "\n",
    "fix_mask = torch.zeros((horizon, obs_dim + act_dim))\n",
    "fix_mask[0, :obs_dim] = 1.\n",
    "loss_weight = torch.ones((horizon, obs_dim + act_dim))\n",
    "loss_weight[0, obs_dim:] = 10.\n",
    "\n",
    "planner = ContinuousDiffusionSDE(\n",
    "    nn_diffusion=nn_diffusion, nn_condition=nn_condition,\n",
    "    fix_mask=fix_mask, loss_weight=loss_weight, ema_rate=0.9999,\n",
    "    device=device)\n",
    "\n",
    "random_obs = torch.randn((obs_dim,))\n",
    "prior = torch.zeros((1, horizon, obs_dim + act_dim))\n",
    "prior[:, 0, :obs_dim] = random_obs[None, :]\n",
    "\n",
    "traj, log = planner.sample(\n",
    "    prior, solver=\"ddpm\", n_samples=1, sample_steps=5)\n",
    "\n",
    "print(f'Trajectory shape: {traj.shape}')\n",
    "print(f'First observation MSE: {(traj[0, 0, :obs_dim].cpu() - random_obs).pow(2).mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that we use some new variables like `fix_mask` and `loss_weight` that we didn't use in tutorial 1. Let's explain them here. \n",
    "\n",
    "The diffusion-generated trajectories are looks like:\n",
    "$$\n",
    "\\bm\\tau = \\left[\n",
    "\\begin{aligned}\n",
    "&\\bm s_0, \\bm s_1, \\cdots, \\bm s_{H-1} \\\\\n",
    "&\\bm a_0, \\bm a_1, \\cdots, \\bm a_{H-1} \\\\\n",
    "\\end{aligned}\n",
    "\\right],\n",
    "$$\n",
    "where $\\bm s_0$ is the current state and it is known and fixed during generation. So the generation process works like an image inpainting task. `fix_mask` is a tensor with the same shape as $\\bm\\tau$ and it is 1 for known items and 0 for unknown items. During training, the fixed parts are maintained and not contributed to the loss. During inference, the fixed parts in `prior` are used to do inpainting. This is why we set `prior[:, 0, :obs_dim] = obs` before sampling.\n",
    "\n",
    "`loss_weight` is also a tensor with the same shape as $\\bm\\tau$ and it is used to weight the loss. In this tutorial, since the first action $\\bm a_0$ directly affects the decision-making performance, we set the weight of the first action to be 10 times larger than the other parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Training the Diffusion Model\n",
    "\n",
    "This part is almost the same as tutorial 1, except that the generated data is the trajectory and the generation condition is the value. You may find it strange that we divide the value tensor by 1200. The 1200 is actually an empirical value that makes the value tensor in the range [0, 1], and is observed in the dataset. It's may be a little bit dumb, but it is simple and works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1000 | Loss: 0.5249495094120502\n",
      "Step: 2000 | Loss: 0.3683495425730944\n",
      "Step: 3000 | Loss: 0.3366451431363821\n",
      "Step: 4000 | Loss: 0.3167404362261295\n",
      "Step: 5000 | Loss: 0.309088200494647\n",
      "Step: 6000 | Loss: 0.3038046252578497\n",
      "Step: 7000 | Loss: 0.2935293935388327\n",
      "Step: 8000 | Loss: 0.290508721485734\n",
      "Step: 9000 | Loss: 0.2891260935664177\n",
      "Step: 10000 | Loss: 0.2836028007864952\n",
      "Step: 11000 | Loss: 0.2813038635402918\n",
      "Step: 12000 | Loss: 0.2795559046268463\n",
      "Step: 13000 | Loss: 0.2781864679157734\n",
      "Step: 14000 | Loss: 0.2767164677679539\n",
      "Step: 15000 | Loss: 0.2739092064350843\n",
      "Step: 16000 | Loss: 0.2731517332792282\n",
      "Step: 17000 | Loss: 0.2720247651785612\n",
      "Step: 18000 | Loss: 0.270441581889987\n",
      "Step: 19000 | Loss: 0.2700309517532587\n",
      "Step: 20000 | Loss: 0.26652422960102556\n",
      "Step: 21000 | Loss: 0.2667119527757168\n",
      "Step: 22000 | Loss: 0.26649457910656926\n",
      "Step: 23000 | Loss: 0.2635034358352423\n",
      "Step: 24000 | Loss: 0.2642084095776081\n",
      "Step: 25000 | Loss: 0.2617920429855585\n",
      "Step: 26000 | Loss: 0.26184875118732454\n",
      "Step: 27000 | Loss: 0.2637613607496023\n",
      "Step: 28000 | Loss: 0.2599382243156433\n",
      "Step: 29000 | Loss: 0.2587474793046713\n",
      "Step: 30000 | Loss: 0.2619900978803635\n",
      "Step: 31000 | Loss: 0.25794452756643294\n",
      "Step: 32000 | Loss: 0.25905107563734053\n",
      "Step: 33000 | Loss: 0.2578494129627943\n",
      "Step: 34000 | Loss: 0.2571191166639328\n",
      "Step: 35000 | Loss: 0.25744552665948867\n",
      "Step: 36000 | Loss: 0.2551538810133934\n",
      "Step: 37000 | Loss: 0.2552723830342293\n",
      "Step: 38000 | Loss: 0.2548257008343935\n",
      "Step: 39000 | Loss: 0.25519646959006786\n",
      "Step: 40000 | Loss: 0.2548497656881809\n",
      "Step: 41000 | Loss: 0.2558991744071245\n",
      "Step: 42000 | Loss: 0.2525263415127993\n",
      "Step: 43000 | Loss: 0.2504307264983654\n",
      "Step: 44000 | Loss: 0.25281058490276337\n",
      "Step: 45000 | Loss: 0.25341033008694647\n",
      "Step: 46000 | Loss: 0.2523557648509741\n",
      "Step: 47000 | Loss: 0.2532037900388241\n",
      "Step: 48000 | Loss: 0.2517930406630039\n",
      "Step: 49000 | Loss: 0.24883080126345158\n",
      "Step: 50000 | Loss: 0.25225999538600447\n",
      "Step: 51000 | Loss: 0.2501875059008598\n",
      "Step: 52000 | Loss: 0.2522296239286661\n",
      "Step: 53000 | Loss: 0.24906157250702382\n",
      "Step: 54000 | Loss: 0.24864947864413262\n",
      "Step: 55000 | Loss: 0.25149074554443357\n",
      "Step: 56000 | Loss: 0.24831301121413707\n",
      "Step: 57000 | Loss: 0.24757667745649814\n",
      "Step: 58000 | Loss: 0.24979127348959446\n",
      "Step: 59000 | Loss: 0.24749108009040355\n",
      "Step: 60000 | Loss: 0.2480992622077465\n",
      "Step: 61000 | Loss: 0.24696154244244098\n",
      "Step: 62000 | Loss: 0.24591872091591357\n",
      "Step: 63000 | Loss: 0.24696750032901765\n",
      "Step: 64000 | Loss: 0.24702321548759937\n",
      "Step: 65000 | Loss: 0.24675247479975224\n",
      "Step: 66000 | Loss: 0.24525296995043755\n",
      "Step: 67000 | Loss: 0.2448580808341503\n",
      "Step: 68000 | Loss: 0.24552739177644253\n",
      "Step: 69000 | Loss: 0.24473671805858613\n",
      "Step: 70000 | Loss: 0.24431452621519564\n",
      "Step: 71000 | Loss: 0.24545120705664158\n",
      "Step: 72000 | Loss: 0.24507873298227786\n",
      "Step: 73000 | Loss: 0.2439378738552332\n",
      "Step: 74000 | Loss: 0.24599356810748577\n",
      "Step: 75000 | Loss: 0.24456173142790794\n",
      "Step: 76000 | Loss: 0.24488239093124867\n",
      "Step: 77000 | Loss: 0.24565517254173755\n",
      "Step: 78000 | Loss: 0.24375731332600117\n",
      "Step: 79000 | Loss: 0.24449335016310214\n",
      "Step: 80000 | Loss: 0.2441640558540821\n",
      "Step: 81000 | Loss: 0.24495141115784644\n",
      "Step: 82000 | Loss: 0.24479996034502982\n",
      "Step: 83000 | Loss: 0.24359911912679671\n",
      "Step: 84000 | Loss: 0.24238001748919488\n",
      "Step: 85000 | Loss: 0.24413877238333226\n",
      "Step: 86000 | Loss: 0.24342429842054844\n",
      "Step: 87000 | Loss: 0.24404762302339078\n",
      "Step: 88000 | Loss: 0.2428428862988949\n",
      "Step: 89000 | Loss: 0.24399424171447753\n",
      "Step: 90000 | Loss: 0.2425030636936426\n",
      "Step: 91000 | Loss: 0.24377728497982026\n",
      "Step: 92000 | Loss: 0.24321288491785525\n",
      "Step: 93000 | Loss: 0.2409370380267501\n",
      "Step: 94000 | Loss: 0.241428294621408\n",
      "Step: 95000 | Loss: 0.2419175636023283\n",
      "Step: 96000 | Loss: 0.24081541395187378\n",
      "Step: 97000 | Loss: 0.24132169756293298\n",
      "Step: 98000 | Loss: 0.23888318341970444\n",
      "Step: 99000 | Loss: 0.2415886250808835\n",
      "Step: 100000 | Loss: 0.2414574002623558\n",
      "Step: 101000 | Loss: 0.24227145493030547\n",
      "Step: 102000 | Loss: 0.24048868983983993\n",
      "Step: 103000 | Loss: 0.24216144490242003\n",
      "Step: 104000 | Loss: 0.24128291353583337\n",
      "Step: 105000 | Loss: 0.23975104714930057\n",
      "Step: 106000 | Loss: 0.24067124633491038\n",
      "Step: 107000 | Loss: 0.23860184203088283\n",
      "Step: 108000 | Loss: 0.2401271387785673\n",
      "Step: 109000 | Loss: 0.24012420746684074\n",
      "Step: 110000 | Loss: 0.24083301176130772\n",
      "Step: 111000 | Loss: 0.24019614206254483\n",
      "Step: 112000 | Loss: 0.23955578833818436\n",
      "Step: 113000 | Loss: 0.23869988992810248\n",
      "Step: 114000 | Loss: 0.23894771006703378\n",
      "Step: 115000 | Loss: 0.2413054277896881\n",
      "Step: 116000 | Loss: 0.23877104051411152\n",
      "Step: 117000 | Loss: 0.23828161409497262\n",
      "Step: 118000 | Loss: 0.23949716487526893\n",
      "Step: 119000 | Loss: 0.23977649812400342\n",
      "Step: 120000 | Loss: 0.23837168948352336\n",
      "Step: 121000 | Loss: 0.23811903244256974\n",
      "Step: 122000 | Loss: 0.24034032900631427\n",
      "Step: 123000 | Loss: 0.23573761232197285\n",
      "Step: 124000 | Loss: 0.23728592829406261\n",
      "Step: 125000 | Loss: 0.2375142975002527\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from cleandiffuser.utils import loop_dataloader\n",
    "\n",
    "\n",
    "savepath = \"../tutorials/results/2_classifier_free_guidance/\"\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=64, shuffle=True, num_workers=4, persistent_workers=True)\n",
    "\n",
    "n_gradient_steps = 0\n",
    "avg_loss = 0.\n",
    "planner.train()\n",
    "for batch in loop_dataloader(dataloader):\n",
    "    \n",
    "    obs, act = batch[\"obs\"][\"state\"].to(device), batch[\"act\"].to(device)\n",
    "    val = batch[\"val\"].to(device) / 1200.\n",
    "    x0 = torch.cat([obs, act], dim=-1)\n",
    "\n",
    "    avg_loss += planner.update(x0=x0, condition=val)[\"loss\"]\n",
    "    \n",
    "    n_gradient_steps += 1\n",
    "    \n",
    "    if n_gradient_steps % 1000 == 0:\n",
    "        print(f'Step: {n_gradient_steps} | Loss: {avg_loss / 1000}')\n",
    "        avg_loss = 0.\n",
    "    \n",
    "    if n_gradient_steps % 100_000 == 0:\n",
    "        planner.save(savepath + \"diffusion.pt\")\n",
    "    \n",
    "    if n_gradient_steps == 500_000:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Evaluation\n",
    "\n",
    "Let's see how our customized CFG planner performs in `halfcheetah-medium-expert-v2`! We parallelly interact with 50 environments and use 3 random seeds to evaluate the performance. The evaluation metric is the normalized episode return, with 100 being the expert-performance and 0 being the random-performance. We use DDPM with 5 sampling steps (compared to 100 sampling steps used in Decision Diffuser official implementation) to generate trajectories. The results show that we can achieve a D4RL score of 88.4. For a model without carefully tuning, this is not bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'savepath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m target_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.95\u001b[39m\n\u001b[1;32m      9\u001b[0m w_cfg \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.2\u001b[39m\n\u001b[0;32m---> 11\u001b[0m planner\u001b[38;5;241m.\u001b[39mload(\u001b[43msavepath\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiffusion.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m planner\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Parallelize evaluation\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'savepath' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "solver = \"ddpm\"\n",
    "sampling_step = 5\n",
    "num_episodes = 3\n",
    "num_envs = 50\n",
    "target_return = 0.95\n",
    "w_cfg = 1.2\n",
    "\n",
    "planner.load(savepath + \"diffusion.pt\")\n",
    "planner.eval()\n",
    "\n",
    "# Parallelize evaluation\n",
    "env_eval = gym.vector.make('halfcheetah-medium-expert-v2', num_envs=num_envs)\n",
    "\n",
    "# Get normalizers\n",
    "normalizer = dataset.get_normalizer()\n",
    "\n",
    "episode_rewards = []\n",
    "\n",
    "prior = torch.zeros((num_envs, horizon, obs_dim + act_dim), device=device)\n",
    "condition = torch.ones((num_envs, 1), device=device) * target_return\n",
    "for i in range(num_episodes):\n",
    "\n",
    "    obs, ep_reward, cum_done, t = env_eval.reset(), 0., 0., 0\n",
    "\n",
    "    while not np.all(cum_done) and t < 1000 + 1:\n",
    "        \n",
    "        # normalize obs\n",
    "        obs = torch.tensor(normalizer.normalize(obs), device=device, dtype=torch.float32)\n",
    "\n",
    "        # sample trajectories\n",
    "        prior[:, 0, :obs_dim] = obs\n",
    "        traj, log = planner.sample(\n",
    "            prior, \n",
    "            solver=solver,\n",
    "            n_samples=num_envs, \n",
    "            sample_step_schedule=\"quad_continuous\",\n",
    "            sample_steps=sampling_step, use_ema=True,\n",
    "            condition_cfg=condition, w_cfg=w_cfg, temperature=1.0)\n",
    "        act = traj[:, 0, obs_dim:].clip(-1., 1.).cpu().numpy()\n",
    "\n",
    "        # step\n",
    "        obs, rew, done, info = env_eval.step(act)\n",
    "\n",
    "        t += 1\n",
    "        cum_done = done if cum_done is None else np.logical_or(cum_done, done)\n",
    "        ep_reward += (rew * (1 - cum_done)) if t < 1000 else rew\n",
    "        print(f'[t={t}] rew: {np.around((rew * (1 - cum_done)), 2)}')\n",
    "\n",
    "    episode_rewards.append(ep_reward)\n",
    "\n",
    "episode_rewards = [list(map(lambda x: env.get_normalized_score(x), r)) for r in episode_rewards]\n",
    "episode_rewards = np.array(episode_rewards)\n",
    "mean_rewards = np.mean(episode_rewards, -1) * 100.\n",
    "print(f'D4RL score: {mean_rewards.mean():.3f} +- {mean_rewards.std():.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleandiffuser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
